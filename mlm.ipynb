{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from os.path import join as pjoin\n",
    "import numpy as np\n",
    "\n",
    "from tokenizer import Tokenizer\n",
    "from dataloader import get_dataloader\n",
    "from model import BERT_MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15611"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "JSON_DIR = \"data/datasets_full\"\n",
    "\n",
    "with open(pjoin(JSON_DIR, \"train.json\"), \"r\") as f:\n",
    "    train_data = f.readlines()\n",
    "train_data = list(map(ast.literal_eval, train_data))\n",
    "\n",
    "tok = Tokenizer(\"tok\", {\"[PAD]\":0, \"[UNK]\":1, \"[MSK]\":2})\n",
    "\n",
    "train_tokens = list(map(lambda x: x[2:], train_data))\n",
    "raw_tokens = [ehr for e in train_tokens for ehr in e]\n",
    "\n",
    "tok.fit(raw_tokens)\n",
    "len(tok.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_dataloader(batch_size=128, drop_last=True, shuffle=True, mode=\"train\", device=\"cpu\", mlm_index=\"all\", json_path=\"data/datasets_full\", tokenizer=tok)\n",
    "valid_dl = get_dataloader(batch_size=128, drop_last=True, shuffle=True, mode=\"valid\", device=\"cpu\", mlm_index=\"all\", json_path=\"data/datasets_full\", tokenizer=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 128\n",
    "device = 'cuda'\n",
    "n_layers = 2\n",
    "\n",
    "model = BERT_MLM(d_model, 2*d_model, tok, dropout=0.2, tokenizer_codes=tok.encoder, device=device)\n",
    "model.load_state_dict(torch.load(\"saved_models/2106_1/2106_1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97db356ffa24bdc87ec042ea9580dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train: loss 2.43; accuracy 0.49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495e6f18ee9848edae9754b9190e01ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/339 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: valid: loss 2.35; accuracy 0.51\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4\n",
    "    )\n",
    "\n",
    "epochs = 1\n",
    "n_prev_epochs = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch = epoch + n_prev_epochs\n",
    "    \n",
    "    model.train(); torch.cuda.empty_cache()\n",
    "    epoch_loss, epoch_acc = [], []\n",
    "\n",
    "    for batch in tqdm(train_dl):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tokens = batch[\"tokens\"].to(device)\n",
    "        targets = batch[\"target_tokens\"].to(device)\n",
    "        \n",
    "        predicted_tokens = model(tokens)\n",
    "\n",
    "        was_mlm_token = tokens == 2\n",
    "        mlm_predicted_tokens = predicted_tokens[was_mlm_token]\n",
    "\n",
    "        loss = criterion(mlm_predicted_tokens, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.detach().item())\n",
    "        epoch_acc.append((targets == mlm_predicted_tokens.argmax(dim=1)).float().mean().item())\n",
    "\n",
    "    epoch_loss = np.array(epoch_loss).mean()\n",
    "    epoch_acc = np.array(epoch_acc).mean()\n",
    "\n",
    "    print(f\"Epoch {1+epoch}:\", \"train: loss {:.2f}; accuracy {:.2f}\".format(epoch_loss, epoch_acc))\n",
    "\n",
    "    model.eval(); torch.cuda.empty_cache()\n",
    "    epoch_loss, epoch_acc = [], []\n",
    "\n",
    "    for batch in tqdm(valid_dl):\n",
    "        tokens = batch[\"tokens\"].to(device)\n",
    "        targets = batch[\"target_tokens\"].to(device)\n",
    "        \n",
    "        predicted_tokens = model(tokens)\n",
    "\n",
    "        was_mlm_token = tokens == 2\n",
    "        mlm_predicted_tokens = predicted_tokens[was_mlm_token]\n",
    "\n",
    "        loss = criterion(mlm_predicted_tokens, targets)\n",
    "        \n",
    "        epoch_loss.append(loss.detach().item())\n",
    "        epoch_acc.append((targets == mlm_predicted_tokens.argmax(dim=1)).float().mean().item())\n",
    "\n",
    "    epoch_loss = np.array(epoch_loss).mean()\n",
    "    epoch_acc = np.array(epoch_acc).mean()\n",
    "\n",
    "    print(f\"Epoch {1+epoch}:\", \"valid: loss {:.2f}; accuracy {:.2f}\".format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"saved_models/2006_1/2006_1.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des AUPRC AUROC pour les 3 classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = get_dataloader(batch_size=128, drop_last=True, shuffle=True, mode=\"test\", device=\"cpu\", mlm_index=\"labels\", json_path=\"data/datasets_full\", tokenizer=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721d9b1c004a4389945f54a3cba10af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/331 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score as AUPRC\n",
    "from sklearn.metrics import roc_auc_score as AUROC\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "classes = [\"dies\", \"readm\", \"duration\"]\n",
    "binary_mapper = {\n",
    "    \"dies\": [268, 27], \n",
    "    \"readm\": [94, 33], \n",
    "    \"duration\": [110, 32]\n",
    "    }\n",
    "\n",
    "labels, binary_probas = {cls:[] for cls in classes}, {cls:[] for cls in classes}\n",
    "\n",
    "for batch in tqdm(test_dl):\n",
    "    tokens = batch[\"tokens\"].to(device)\n",
    "    targets = batch[\"target_tokens\"].to(device)\n",
    "    \n",
    "    predicted_logits = model(tokens)\n",
    "\n",
    "    was_mlm_index = tokens == 2\n",
    "    mlm_predicted_logits = predicted_logits[was_mlm_index]\n",
    "    predicted_tokens = mlm_predicted_logits.argmax(dim=1)\n",
    "\n",
    "    predicted_tokens = predicted_tokens.reshape((-1, 3)).to('cpu').detach().numpy()\n",
    "    targets = targets.reshape((-1, 3)).to('cpu').detach().numpy()\n",
    "\n",
    "    for idx, inference_type in enumerate(classes):\n",
    "        y_true = targets[:, idx]\n",
    "\n",
    "        one, zero = binary_mapper[inference_type]\n",
    "\n",
    "        slicer = torch.tensor([zero, one])\n",
    "        logits_of_interest = mlm_predicted_logits[idx::len(classes), slicer]\n",
    "        probas_of_interest = torch.nn.Softmax(dim=-1)(logits_of_interest).to('cpu').detach().numpy()\n",
    "        probas_of_interest = probas_of_interest[:, 1]\n",
    "\n",
    "        y_true_binary = np.where(y_true == one, np.ones_like(y_true), np.zeros_like(y_true))\n",
    "\n",
    "        labels[inference_type].append(y_true_binary)\n",
    "        binary_probas[inference_type].append(probas_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {k:np.concatenate(v) for k,v in labels.items()}\n",
    "binary_probas = {k:np.concatenate(v) for k,v in binary_probas.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9658790107167533, 0.7097040795501505, 0.955183383320384)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUROC(labels[\"duration\"], binary_probas[\"duration\"]), AUROC(labels[\"readm\"], binary_probas[\"readm\"]), AUROC(labels[\"dies\"], binary_probas[\"dies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8417071276100196, 0.38326588444974463, 0.7043190907372763)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUPRC(labels[\"duration\"], binary_probas[\"duration\"]), AUPRC(labels[\"readm\"], binary_probas[\"readm\"]), AUPRC(labels[\"dies\"], binary_probas[\"dies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unige",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
